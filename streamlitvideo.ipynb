{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" # importing all necessary libraries\n\nimport av\nimport cv2\nimport numpy as np\nimport streamlit as st        \nfrom aiortc.contrib.media import MediaPlayer\nfrom streamlit_webrtc import VideoTransformerBase, webrtc_streamer\nimport cv2\nfrom streamlit_webrtc import VideoTransformerBase, webrtc_streamer     #streamlit-webrtc helps to deal with real-time video streams.\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras \nfrom tensorflow.keras import layers\n\n\nmy_model = tf.keras.models.load_model('../input/model5/model.h5')   \nclass VideoTransformer(VideoTransformerBase): \n    def transform(self, frame):                                                            \n        img = frame.to_ndarray(format=\"bgr24\")                                              \n        face_detect = cv2.CascadeClassifier('../input/model56/haarcascade_frontalface_default.xml')          \n        #eye_detect = cv2.CascadeClassifier('haarcascade_eye.xml')\n        \n        class_labels = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']        \n\n\n\n        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)                 \n        face_roi = face_detect.detectMultiScale(img_gray, 1.3,1)          \n        if face_roi is ():                                                \n            return img\n\n        for(x,y,w,h) in face_roi:                                          \n            x = x - 5\n            w = w + 10\n            y = y + 7\n            h = h + 2\n            cv2.rectangle(img, (x,y),(x+w,y+h),(125,125,10), 2)             \n            img_color_crop = img[y:y+h,x:x+w]                             \n            final_image = cv2.resize(img_color_crop, (48,48))          \n            final_image = np.expand_dims(final_image, axis = 0)           \n            final_image = final_image/255.0                               \n            prediction = my_model.predict(final_image)                    \n            label=class_labels[prediction.argmax()]                        \n            cv2.putText(img,label, (50,60), cv2.FONT_HERSHEY_SCRIPT_COMPLEX,2, (120,10,200),3)    \n                                                     \n                                                      \n                                                      \n       \n        return img\n\nwebrtc_streamer(key=\"example\", video_transformer_factory=VideoTransformer)      ","metadata":{"_uuid":"d27c13bc-7cab-49d6-8b20-c37a7971384d","_cell_guid":"ce97880a-e59b-454b-bdcb-6a08f1c28fea","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}