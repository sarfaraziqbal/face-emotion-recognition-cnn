{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The code in this file helps us to open the webcam , detect the faces and with the help of our model detect the emotions","metadata":{}},{"cell_type":"code","source":"# importing all necessary libraries\n\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nimport os\n\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras \nfrom tensorflow.keras import layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncv2.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading .h5 file and storing\n\nmy_model = tf.keras.models.load_model('../input/h5files/model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_detect = cv2.CascadeClassifier('../input/haarcascade/haarcascade_frontalface_alt.xml')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  loading cascade classifier\nface_detect = cv2.CascadeClassifier('../input/haarcascade/haarcascade_frontalface_default.xml')  \n\n\ndef face_detection(img,size=0.5):\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)              # converting image into grayscale\n    face_roi = face_detect.detectMultiScale(img_gray, 1.3,1)      \n    \n    \n    if face_roi is ():                                        \n        return img\n\n    for(x,y,w,h) in face_roi:                                \n        x = x - 5\n        w = w + 10\n        y = y + 7\n        h = h + 2\n        cv2.rectangle(img, (x,y),(x+w,y+h),(125,125,10), 1)      \n        img_gray_crop = img_gray[y:y+h,x:x+w]                    \n        img_color_crop = img[y:y+h,x:x+w]                        \n        \n        \n        final_image = cv2.resize(img_color_crop, (64,64))      \n        final_image = np.expand_dims(final_image, axis = 0)     \n        final_image = final_image/255.0                          \n    \n        prediction = my_model3.predict(final_image)              \n        label=class_labels[prediction.argmax()]                   \n        cv2.putText(frame,label, (50,60), cv2.FONT_HERSHEY_SCRIPT_COMPLEX,2, (120,10,200),3)  \n                                                     \n\n\n    img_color_crop = cv2.flip(img_color_crop, 1)      # fliping the image\n    return img\n\ncap = cv2.VideoCapture(0)                    # capture the video live webcam\n\nwhile True:\n    ret, frame = cap.read()\n    cv2.imshow('LIVE', face_detection(frame))          \n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}