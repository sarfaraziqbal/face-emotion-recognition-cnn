{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The code in this file helps us to open the webcam , detect the faces and with the help of our model detect the emotions","metadata":{}},{"cell_type":"code","source":"# importing all necessary libraries\n\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nimport os\n\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras \nfrom tensorflow.keras import layers","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\ncv2.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading .h5 file and storing\n\nmy_model = tf.keras.models.load_model('../input/h5files/model.h5')","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"face_detect = cv2.CascadeClassifier('../input/haarcascade/haarcascade_frontalface_alt.xml')","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class_labels = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#  loading cascade classifier\nface_detect = cv2.CascadeClassifier('../input/haarcascade/haarcascade_frontalface_default.xml')  \n\n\ndef face_detection(img,size=0.5):\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)              # converting image into grayscale\n    face_roi = face_detect.detectMultiScale(img_gray, 1.3,1)      \n    \n    \n    if face_roi is ():                                        \n        return img\n\n    for(x,y,w,h) in face_roi:                                \n        x = x - 5\n        w = w + 10\n        y = y + 7\n        h = h + 2\n        cv2.rectangle(img, (x,y),(x+w,y+h),(125,125,10), 1)      \n        img_gray_crop = img_gray[y:y+h,x:x+w]                    \n        img_color_crop = img[y:y+h,x:x+w]                        \n        \n        \n        final_image = cv2.resize(img_color_crop, (64,64))      \n        final_image = np.expand_dims(final_image, axis = 0)     \n        final_image = final_image/255.0                          \n    \n        prediction = my_model3.predict(final_image)              \n        label=class_labels[prediction.argmax()]                   \n        cv2.putText(frame,label, (50,60), cv2.FONT_HERSHEY_SCRIPT_COMPLEX,2, (120,10,200),3)  \n                                                     \n\n\n    img_color_crop = cv2.flip(img_color_crop, 1)      # fliping the image\n    return img\n\ncap = cv2.VideoCapture(0)                    # capture the video live webcam\n\nwhile True:\n    ret, frame = cap.read()\n    cv2.imshow('LIVE', face_detection(frame))          \n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()","metadata":{"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-55452529104c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LIVE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-55452529104c>\u001b[0m in \u001b[0;36mface_detection\u001b[0;34m(img, size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mface_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimg_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# converting image into grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mface_roi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-tk9iuyva/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"],"ename":"error","evalue":"OpenCV(4.5.1) /tmp/pip-req-build-tk9iuyva/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}